# 容积表诊断与校正平台

业务，从加油站采集传感器数据上传到服务端进行解析和处理。项目架构分为一个server端负责接受站端数据，解析计算，将整合好的数据展示给用户看。

技术难点：server端同时需要对接数百个站端，每个站端会实时传数据到server端。因此sever会承受较大的数据处理压力。
目前为缓解server端的压力采取的措施，
1. 使用MQ来来解耦站端和sever端的数据收发。站端的数据会根据类型路由到不同的队列中，服务端设置不同的监听器来获取不同队列中的数据进行处理。
2. 使用redis来缓存基础数据，减少在计算时与数据库的查询次数。
3. 对数据量较多的数据进行分片处理。
   然后，平常做的工作就是写数据的处理方式，然后由于大部分数据处理逻辑有很强的相同性，然后我就使用了一下模板方法，
   把处理流程抽象了一下，之后不同的数据继承abstractProcess，来实现对应的处理方法就行了。
   之前项目从mq获取数据的时候，没有考虑到数据重复消费的问题。因为使用的是rabbitmq，它实现的是AMQP（高级消息队列协议），它保证`至少传递一次消息`,
   但是不保证消息不重复消费，我们使用的是由消费者进行手动ack，所以这里会有一个问题：就是如果因为网络波动消费者没有及时回确认，那这个消息就会被重新放回队列。
   然后可能会导致消息重复被消费。因为我们这个从MQ取数据之后的操作大多数都是写操作，所以再数据库层面不是幂等的。当然因为一些数据设置了唯一索引，
   这些数据即使重复消费也不会插入重复的数据，但是这样毕竟不太好。而且有些数据由于数据量不是很大，没有设置唯一索引，这样的话就可能导致有些数据重复插入。
   所以我们需要在业务层面来解决幂等操作的问题。一开始我想的是，因为读操作是天然幂等的，只有写操作会有问题。所以可以通过AOP，在所有写书操作之前加个before方法，然后验证一下。
   后来发现，没这必要，因为我们所有的消息都是 有个时间戳的，而且消息的产生是严格按照时间顺序产生的。所以只要每次消费完消息之后，在redis中记录一下这次消费消息的事件，
   如果下次碰到同样的消息了，那就直接丢弃，然后回复确认就行。

另外的话，其实我是由把我当前的项目改成分布式架构的想法的。因为，我们目前的sever端是单体的，之前就出现过OOM问题导致整个服务挂掉，所有数据都丢失了。
因为单体应用绕不开的问题就是单体故障嘛，另外还有服务器的请求连接的限制，和数据容量问题。所以其实我想把它改造成分布式的项目，而且已经有一些想法和实施了。
因为还没和主管沟通过，所以我只是加了一些服务监控的东西，spring cloud admin。监控所有连入的站端服务和sever端服务，这个刚开始搞，我其实还想加个短信报警，
就是有那台服务的某个端点抛异常了，就直接进行短信提醒的。但是现在我还有文档整理的任务，加上面试也挺多的，估计应该搞不完了，挺遗憾的。